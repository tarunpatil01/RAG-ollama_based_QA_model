{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF RAG Implementation with Advanced OCR\n",
    "\n",
    "This notebook demonstrates a Retrieval-Augmented Generation (RAG) system for PDF documents with improved OCR capabilities that filter out gibberish text and optimize processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import ollama\n",
    "import cv2\n",
    "import pytesseract\n",
    "import nltk\n",
    "from nltk.corpus import words as nltk_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "from collections import Counter\n",
    "import time\n",
    "import hashlib\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Set the path to Tesseract if needed\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\path\\to\\tesseract.exe\"  # Uncomment and set your path\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "\n",
    "# Create a set of English words for checking\n",
    "ENGLISH_WORDS = set(w.lower() for w in nltk_words.words())\n",
    "COMMON_WORDS = set(['the', 'and', 'to', 'of', 'a', 'in', 'that', 'is', 'was', 'for'])\n",
    "\n",
    "# Cache directory for OCR results\n",
    "CACHE_DIR = os.path.join(os.getcwd(), \"ocr_cache\")\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in e:\\anaconda\\envs\\rag\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: faiss-cpu in e:\\anaconda\\envs\\rag\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: PyPDF2 in e:\\anaconda\\envs\\rag\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipywidgets) (8.33.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from faiss-cpu) (2.2.3)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\envs\\rag\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in e:\\anaconda\\envs\\rag\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in e:\\anaconda\\envs\\rag\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in e:\\anaconda\\envs\\rag\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets faiss-cpu PyPDF2 pytesseract opencv-python nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Text Extraction from PDF with OCR Fallback\n",
    "def extract_text_from_pdfs(uploaded_files):\n",
    "    text = \"\"\n",
    "    for uploaded_file in uploaded_files:\n",
    "        reader = PyPDF2.PdfReader(uploaded_file)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            page_text = page.extract_text()\n",
    "            \n",
    "            # If PDF contains extractable text\n",
    "            if page_text and len(page_text.strip()) > 100:\n",
    "                text += f\"[Page {i+1}] {page_text}\\n\"\n",
    "            # If the page has little or no text, it might be a scanned image\n",
    "            else:\n",
    "                try:\n",
    "                    # For notebooks, we would need a more complex implementation to handle image-based PDFs\n",
    "                    # This is a simplified version\n",
    "                    print(f\"Page {i+1} has little text, might need OCR\")\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "            text += \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Chunking the Text\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - chunk_overlap\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Embedding Text using Ollama (mxbai-embed-large)\n",
    "def get_embedding(text):\n",
    "    response = ollama.embeddings(\n",
    "        model=\"mxbai-embed-large\",\n",
    "        prompt=f\"Represent this sentence for searching relevant passages: {text}\"\n",
    "    )\n",
    "    return np.array(response[\"embedding\"], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Build FAISS Index\n",
    "def build_faiss_index(chunks):\n",
    "    vectors = [get_embedding(chunk) for chunk in chunks]\n",
    "    dim = len(vectors[0])\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(vectors))\n",
    "    return index, chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Retrieve Context from Query\n",
    "def retrieve_context(index, chunks, query, k=1):\n",
    "    query_embedding = get_embedding(query).reshape(1, -1)\n",
    "    _, indices = index.search(query_embedding, k)\n",
    "    return \"\\n\".join([chunks[i] for i in indices[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Ask Mistral (via Ollama)\n",
    "def ask_mistral(context, question):\n",
    "    prompt = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Improved OCR Performance with Caching\n",
    "def get_file_hash(file_bytes):\n",
    "    \"\"\"Generate a hash for file bytes to use as a cache key\"\"\"\n",
    "    return hashlib.md5(file_bytes).hexdigest()\n",
    "\n",
    "def cache_result(cache_key, result):\n",
    "    \"\"\"Cache the OCR result for future use\"\"\"\n",
    "    try:\n",
    "        cache_file = os.path.join(CACHE_DIR, f\"{cache_key}.pkl\")\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error caching result: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def get_cached_result(cache_key):\n",
    "    \"\"\"Try to get cached OCR result\"\"\"\n",
    "    try:\n",
    "        cache_file = os.path.join(CACHE_DIR, f\"{cache_key}.pkl\")\n",
    "        if os.path.exists(cache_file):\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading cache: {str(e)}\")\n",
    "    return None\n",
    "\n",
    "def is_gibberish(text, threshold=0.25):\n",
    "    \"\"\"\n",
    "    Check if text appears to be gibberish - optimized version\n",
    "    \"\"\"\n",
    "    if not text or not isinstance(text, str) or len(text.strip()) < 5:\n",
    "        return True\n",
    "        \n",
    "    # Clean the text\n",
    "    text = text.strip().lower()\n",
    "    words = re.findall(r'\\b[a-z]{2,}\\b', text)\n",
    "    \n",
    "    if not words:\n",
    "        return True\n",
    "    \n",
    "    # Quick check for real English words (sample a subset for speed)\n",
    "    sample_size = min(len(words), 20)  # Check at most 20 words for speed\n",
    "    sample_words = words[:sample_size]\n",
    "    real_word_count = sum(1 for w in sample_words if w in ENGLISH_WORDS or w in COMMON_WORDS)\n",
    "    word_ratio = real_word_count / max(1, len(sample_words))\n",
    "    \n",
    "    # Calculate overall gibberish score\n",
    "    gibberish_score = (1 - word_ratio) * 0.7\n",
    "    \n",
    "    return gibberish_score > threshold\n",
    "\n",
    "def clean_ocr_text(text):\n",
    "    \"\"\"Clean common OCR artifacts - optimized version\"\"\"\n",
    "    if not text:\n",
    "        return text\n",
    "        \n",
    "    # Most important replacements for speed\n",
    "    text = re.sub(r'\\b[A-Z]{5,}\\b', ' ', text)  # Remove all-caps gibberish words\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n",
    "    text = re.sub(r'[\\r\\n]+', '\\n', text)       # Normalize line breaks\n",
    "    text = re.sub(r'\\s+', ' ', text)            # Normalize whitespace\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 1 PDF(s) and created vector store with 3 chunks.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Run RAG with Performance Metrics\n",
    "# Provide your PDF file names here (they must be in the same folder as the notebook)\n",
    "pdf_files = [\"test file.pdf\"]  # 📝 Replace with your file names\n",
    "pdf_paths = [os.path.join(os.getcwd(), f) for f in pdf_files]\n",
    "\n",
    "# Extract → Chunk → Embed → Build Index\n",
    "start_time = time.time()\n",
    "raw_text = extract_text_from_pdfs(pdf_paths)\n",
    "chunks = chunk_text(raw_text)\n",
    "index, chunks = build_faiss_index(chunks)\n",
    "processing_time = time.time() - start_time\n",
    "print(f\"✅ Processed {len(pdf_files)} PDF(s) and created vector store with {len(chunks)} chunks.\")\n",
    "print(f\"⏱️ Processing time: {processing_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Question:** who did Emma call?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Answer:**  Emma called her best friend Jake."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10: Hardcoded Question and Answer with Timing\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# 🔽 Replace this with your custom question\n",
    "question = \"who did Emma call?\"\n",
    "\n",
    "if not chunks or not index:\n",
    "    print(\"Please process your PDFs first.\")\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    context = retrieve_context(index, chunks, question)\n",
    "    answer = ask_mistral(context, question)\n",
    "    query_time = time.time() - start_time\n",
    "\n",
    "    display(Markdown(f\"**Question:** {question}\"))\n",
    "    display(Markdown(f\"**Answer:** {answer}\"))\n",
    "    print(f\"⏱️ Query time: {query_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Parallel Processing Demonstration\n",
    "def process_in_parallel(items, process_func, max_workers=None):\n",
    "    \"\"\"Process items in parallel and measure performance\"\"\"\n",
    "    start_time = time.time()\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(process_func, item) for item in items]\n",
    "        for future in futures:\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in parallel processing: {e}\")\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Processed {len(items)} items in {elapsed_time:.2f} seconds\")\n",
    "    return results\n",
    "\n",
    "# Example dummy function to demonstrate parallelization\n",
    "def dummy_processor(text):\n",
    "    time.sleep(0.1)  # Simulate processing time\n",
    "    return len(text)\n",
    "\n",
    "# Test with and without parallelization\n",
    "test_items = [\"text\" + str(i) * 100 for i in range(10)]\n",
    "\n",
    "print(\"Sequential processing:\")\n",
    "start = time.time()\n",
    "sequential_results = [dummy_processor(item) for item in test_items]\n",
    "print(f\"Time taken: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "print(\"\\nParallel processing:\")\n",
    "parallel_results = process_in_parallel(test_items, dummy_processor)\n",
    "print(f\"Results match: {sequential_results == parallel_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Demo OCR on an image file with performance measurement\n",
    "# Uncomment to test with your own image\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image file\n",
    "image_path = \"sample_image.jpg\"  # Replace with your image path\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Calculate image hash for potential caching\n",
    "img_hash = hashlib.md5(img.tobytes()).hexdigest()\n",
    "cached_text = get_cached_result(img_hash)\n",
    "\n",
    "if cached_text:\n",
    "    print(\"Using cached OCR result\")\n",
    "    text = cached_text\n",
    "else:\n",
    "    print(\"Running OCR...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply adaptive threshold\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Extract text with Tesseract\n",
    "    text = pytesseract.image_to_string(thresh)\n",
    "    cleaned_text = clean_ocr_text(text)\n",
    "    \n",
    "    # Cache the result\n",
    "    cache_result(img_hash, cleaned_text)\n",
    "    \n",
    "    ocr_time = time.time() - start_time\n",
    "    print(f\"OCR completed in {ocr_time:.2f} seconds\")\n",
    "    \n",
    "    text = cleaned_text\n",
    "\n",
    "# Check if the text is gibberish\n",
    "gibberish = is_gibberish(text)\n",
    "\n",
    "# Display image and text\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title(\"Preprocessed Image\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f\"Extracted text: {'(GIBBERISH DETECTED)' if gibberish else ''}\")\n",
    "print(text)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
